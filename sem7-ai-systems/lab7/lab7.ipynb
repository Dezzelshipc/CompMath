{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Text generation with simple RNN\n",
    "\n",
    "* [Old tensorflow](https://www.tensorflow.org/text/tutorials/text_generation)\n",
    "* [mlnuggets](https://www.machinelearningnuggets.com/tensorflow-lstm/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers, Model, Sequential, ops\n",
    "from keras.layers import TextVectorization\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20594\n"
     ]
    }
   ],
   "source": [
    "name_url = (\"Crime and Punishment\", 'https://www.gutenberg.org/files/2554/2554-0.txt')\n",
    "\n",
    "filepath = keras.utils.get_file(f'{name_url[0]}.txt', origin=name_url[1])\n",
    "text_f = ''\n",
    "with open(filepath, encoding='utf-8') as f:\n",
    "    text_f = f.read()[10000:] # skip preface +-\n",
    "\n",
    "text = text_f\n",
    "\n",
    "text = re.sub(r\"[\\\"\\`\\'\\’\\“\\”]\", r\"\", text_f)\n",
    "text = re.sub(r\"[\\(\\)]\", r\"\", text_f)\n",
    "text = re.sub(r\"[\\.\\!\\?]\", \"!\", text)\n",
    "text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "text_list = text.replace('\\n', ' ').split('!')\n",
    "text_list = list(map(lambda x: x.strip(), text_list))\n",
    "print( len(text_list) )\n",
    "\n",
    "text_list = list(filter(None, text_list))\n",
    "\n",
    "import random\n",
    "random.shuffle(text_list)\n",
    "\n",
    "length = len(text_list)\n",
    "text_train = text_list[:int(0.8*length)]\n",
    "text_valid = text_list[int(0.8*length):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736245521.827899 3631601 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 842 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:04:00.0, compute capability: 8.0\n",
      "I0000 00:00:1736245521.831166 3631601 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 32374 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0\n",
      "I0000 00:00:1736245521.833584 3631601 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 32362 MB memory:  -> device: 2, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:85:00.0, compute capability: 8.0\n",
      "I0000 00:00:1736245521.836447 3631601 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 32374 MB memory:  -> device: 3, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:89:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11697\n"
     ]
    }
   ],
   "source": [
    "words = sorted([(len(a:=line.split(\" \")), a, line) for line in text_list], reverse=1)\n",
    "MAX_LEN = max([len(line.split(\" \")) for line in text_list])\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_LEN + 1,\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(text_list)\n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "print(len(vocab))\n",
    "\n",
    "word_from_id = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=\"\", oov_token=\"[UNK]\",  invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 128\n",
    "\n",
    "def preprocess(text_l: list):\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        text = tf.expand_dims(text, -1)\n",
    "        tokenized_sentences = vectorize_layer(text)\n",
    "        x = tokenized_sentences[:, :-1]\n",
    "        y = tokenized_sentences[:, 1:]\n",
    "        return x, y\n",
    "    \n",
    "    return (\n",
    "        tf.data.Dataset.from_tensor_slices(text_l)\n",
    "            .shuffle(BUFFER_SIZE)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .map(preprocess_text)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "dataset_train = preprocess(text_train)\n",
    "dataset_valid = preprocess(text_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__()\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(BATCH_SIZE)\n",
    "    x = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "rnn_units = 512\n",
    "\n",
    "model = MyModel(len(vocab), embedding_dim, rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_model_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,497,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">986,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11697</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,000,561</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m102\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │     \u001b[38;5;34m1,497,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m102\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m986,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m102\u001b[0m, \u001b[38;5;34m11697\u001b[0m)       │     \u001b[38;5;34m6,000,561\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,451,669</span> (97.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,451,669\u001b[0m (97.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,483,889</span> (32.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,483,889\u001b[0m (32.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,967,780</span> (64.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m16,967,780\u001b[0m (64.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 102)\n",
      "(16, 102)\n",
      "(16, 102, 11697)\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_train in dataset_train.take(1):\n",
    "    ex_m = model(X_train)\n",
    "    pass\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(ex_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 20:41:03.644986: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_0_bfc) ran out of memory trying to allocate 365.53MiB (rounded to 383287296)requested by op StatefulPartitionedCall/gradient_tape/my_model_2_1/dense_2_1/MatMul/MatMul_1\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-01-07 20:41:03.645041: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1053] BFCAllocator dump for GPU_0_bfc\n",
      "2025-01-07 20:41:03.645056: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (256): \tTotal Chunks: 46, Chunks in use: 46. 11.5KiB allocated for chunks. 11.5KiB in use in bin. 245B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645064: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (512): \tTotal Chunks: 1, Chunks in use: 0. 768B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645073: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645079: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645086: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645094: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (8192): \tTotal Chunks: 7, Chunks in use: 5. 88.2KiB allocated for chunks. 63.5KiB in use in bin. 61.5KiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645101: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 21.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645109: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (32768): \tTotal Chunks: 6, Chunks in use: 6. 279.2KiB allocated for chunks. 279.2KiB in use in bin. 246.8KiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645117: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (65536): \tTotal Chunks: 3, Chunks in use: 2. 280.0KiB allocated for chunks. 183.0KiB in use in bin. 182.7KiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645124: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645149: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645156: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (524288): \tTotal Chunks: 4, Chunks in use: 4. 3.05MiB allocated for chunks. 3.05MiB in use in bin. 3.05MiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645162: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.30MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645170: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (2097152): \tTotal Chunks: 5, Chunks in use: 4. 15.31MiB allocated for chunks. 12.27MiB in use in bin. 12.19MiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645178: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (4194304): \tTotal Chunks: 5, Chunks in use: 5. 30.19MiB allocated for chunks. 30.19MiB in use in bin. 24.08MiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645185: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (8388608): \tTotal Chunks: 2, Chunks in use: 0. 22.34MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645192: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (16777216): \tTotal Chunks: 3, Chunks in use: 3. 64.82MiB allocated for chunks. 64.82MiB in use in bin. 64.82MiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645199: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 0. 97.97MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645208: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 77.67MiB allocated for chunks. 77.67MiB in use in bin. 72.82MiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645216: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (134217728): \tTotal Chunks: 3, Chunks in use: 1. 528.94MiB allocated for chunks. 132.66MiB in use in bin. 72.82MiB client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645223: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-07 20:41:03.645231: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1076] Bin for 365.53MiB was 256.00MiB, Chunk State: \n",
      "2025-01-07 20:41:03.645238: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1089] Next region of size 883163136\n",
      "2025-01-07 20:41:03.645248: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da000000 of size 1280 next 1\n",
      "2025-01-07 20:41:03.645254: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da000500 of size 256 next 2\n",
      "2025-01-07 20:41:03.645265: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da000600 of size 256 next 3\n",
      "2025-01-07 20:41:03.645270: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da000700 of size 256 next 10\n",
      "2025-01-07 20:41:03.645276: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da000800 of size 256 next 12\n",
      "2025-01-07 20:41:03.645281: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da000900 of size 256 next 6\n",
      "2025-01-07 20:41:03.645287: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da000a00 of size 93696 next 7\n",
      "2025-01-07 20:41:03.645293: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da017800 of size 93696 next 4\n",
      "2025-01-07 20:41:03.645299: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02e600 of size 256 next 5\n",
      "2025-01-07 20:41:03.645304: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02e700 of size 256 next 9\n",
      "2025-01-07 20:41:03.645310: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02e800 of size 256 next 13\n",
      "2025-01-07 20:41:03.645315: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02e900 of size 256 next 8\n",
      "2025-01-07 20:41:03.645321: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02ea00 of size 256 next 11\n",
      "2025-01-07 20:41:03.645326: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02eb00 of size 256 next 14\n",
      "2025-01-07 20:41:03.645331: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02ec00 of size 256 next 15\n",
      "2025-01-07 20:41:03.645337: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02ed00 of size 256 next 17\n",
      "2025-01-07 20:41:03.645342: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02ee00 of size 256 next 18\n",
      "2025-01-07 20:41:03.645347: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da02ef00 of size 256 next 19\n",
      "2025-01-07 20:41:03.645353: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70da02f000 of size 13056 next 67\n",
      "2025-01-07 20:41:03.645358: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da032300 of size 13056 next 78\n",
      "2025-01-07 20:41:03.645364: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da035600 of size 45312 next 28\n",
      "2025-01-07 20:41:03.645369: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da040700 of size 256 next 77\n",
      "2025-01-07 20:41:03.645375: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70da040800 of size 12288 next 73\n",
      "2025-01-07 20:41:03.645381: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da043800 of size 256 next 66\n",
      "2025-01-07 20:41:03.645387: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da043900 of size 256 next 45\n",
      "2025-01-07 20:41:03.645393: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70da043a00 of size 9353216 next 25\n",
      "2025-01-07 20:41:03.645398: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92f200 of size 256 next 22\n",
      "2025-01-07 20:41:03.645404: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92f300 of size 256 next 27\n",
      "2025-01-07 20:41:03.645409: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92f400 of size 256 next 23\n",
      "2025-01-07 20:41:03.645415: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92f500 of size 256 next 34\n",
      "2025-01-07 20:41:03.645420: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92f600 of size 256 next 113\n",
      "2025-01-07 20:41:03.645426: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70da92f700 of size 768 next 61\n",
      "2025-01-07 20:41:03.645437: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92fa00 of size 256 next 64\n",
      "2025-01-07 20:41:03.645442: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92fb00 of size 256 next 130\n",
      "2025-01-07 20:41:03.645448: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92fc00 of size 256 next 109\n",
      "2025-01-07 20:41:03.645453: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92fd00 of size 256 next 58\n",
      "2025-01-07 20:41:03.645467: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92fe00 of size 256 next 99\n",
      "2025-01-07 20:41:03.645473: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da92ff00 of size 256 next 57\n",
      "2025-01-07 20:41:03.645478: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da930000 of size 256 next 31\n",
      "2025-01-07 20:41:03.645484: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da930100 of size 256 next 62\n",
      "2025-01-07 20:41:03.645489: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70da930200 of size 256 next 16\n",
      "2025-01-07 20:41:03.645495: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70da930300 of size 170379776 next 76\n",
      "2025-01-07 20:41:03.645501: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e4bacd00 of size 12288 next 103\n",
      "2025-01-07 20:41:03.645506: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e4bafd00 of size 15104 next 49\n",
      "2025-01-07 20:41:03.645514: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e4bb3800 of size 3342336 next 70\n",
      "2025-01-07 20:41:03.645519: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e4ee3800 of size 5377280 next 116\n",
      "2025-01-07 20:41:03.645525: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404500 of size 256 next 94\n",
      "2025-01-07 20:41:03.645530: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404600 of size 256 next 117\n",
      "2025-01-07 20:41:03.645536: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404700 of size 256 next 95\n",
      "2025-01-07 20:41:03.645541: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404800 of size 256 next 92\n",
      "2025-01-07 20:41:03.645547: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404900 of size 256 next 111\n",
      "2025-01-07 20:41:03.645552: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404a00 of size 256 next 118\n",
      "2025-01-07 20:41:03.645558: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404b00 of size 256 next 104\n",
      "2025-01-07 20:41:03.645563: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404c00 of size 256 next 114\n",
      "2025-01-07 20:41:03.645569: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404d00 of size 256 next 97\n",
      "2025-01-07 20:41:03.645575: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404e00 of size 256 next 56\n",
      "2025-01-07 20:41:03.645580: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5404f00 of size 256 next 106\n",
      "2025-01-07 20:41:03.645586: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5405000 of size 256 next 101\n",
      "2025-01-07 20:41:03.645591: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5405100 of size 256 next 110\n",
      "2025-01-07 20:41:03.645597: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e5405200 of size 256 next 121\n",
      "2025-01-07 20:41:03.645602: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70e5405300 of size 22016 next 69\n",
      "2025-01-07 20:41:03.645608: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e540a900 of size 3232768 next 80\n",
      "2025-01-07 20:41:03.645614: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70e571fd00 of size 81440768 next 52\n",
      "2025-01-07 20:41:03.645620: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70ea4cad00 of size 46848 next 119\n",
      "2025-01-07 20:41:03.645626: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70ea4d6400 of size 46848 next 120\n",
      "2025-01-07 20:41:03.645631: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70ea4e1b00 of size 12288 next 83\n",
      "2025-01-07 20:41:03.645637: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70ea4e4b00 of size 53248 next 100\n",
      "2025-01-07 20:41:03.645643: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70ea4f1b00 of size 3192576 next 102\n",
      "2025-01-07 20:41:03.645648: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70ea7fd200 of size 5988864 next 96\n",
      "2025-01-07 20:41:03.645654: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70eadb3400 of size 3145728 next 108\n",
      "2025-01-07 20:41:03.645661: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70eb0b3400 of size 46848 next 60\n",
      "2025-01-07 20:41:03.645667: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70eb0beb00 of size 99328 next 139\n",
      "2025-01-07 20:41:03.645673: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70eb0d6f00 of size 46848 next 126\n",
      "2025-01-07 20:41:03.645678: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70eb0e2600 of size 12288 next 123\n",
      "2025-01-07 20:41:03.645684: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70eb0e5600 of size 46422272 next 29\n",
      "2025-01-07 20:41:03.645689: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70edd2af00 of size 786432 next 124\n",
      "2025-01-07 20:41:03.645698: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70eddeaf00 of size 835584 next 79\n",
      "2025-01-07 20:41:03.645704: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70edeb6f00 of size 1359872 next 98\n",
      "2025-01-07 20:41:03.645709: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70ee002f00 of size 786432 next 115\n",
      "2025-01-07 20:41:03.645715: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70ee0c2f00 of size 786432 next 129\n",
      "2025-01-07 20:41:03.645720: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70ee182f00 of size 7561728 next 107\n",
      "2025-01-07 20:41:03.645727: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70ee8b9100 of size 5988864 next 112\n",
      "2025-01-07 20:41:03.645733: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70eee6f300 of size 23955456 next 125\n",
      "2025-01-07 20:41:03.645739: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70f0547b00 of size 3145728 next 143\n",
      "2025-01-07 20:41:03.645744: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70f0847b00 of size 14074368 next 142\n",
      "2025-01-07 20:41:03.645762: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70f15b3d00 of size 6735360 next 105\n",
      "2025-01-07 20:41:03.645768: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70f1c20300 of size 23955456 next 91\n",
      "2025-01-07 20:41:03.645773: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70f32f8b00 of size 20054272 next 87\n",
      "2025-01-07 20:41:03.645779: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f70f4618c00 of size 56303872 next 93\n",
      "2025-01-07 20:41:03.645784: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f70f7bcad00 of size 139102208 next 54\n",
      "2025-01-07 20:41:03.645790: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f7100073500 of size 245156608 next 18446744073709551615\n",
      "2025-01-07 20:41:03.645796: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114]      Summary of in-use Chunks by size: \n",
      "2025-01-07 20:41:03.645804: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 46 Chunks of size 256 totalling 11.5KiB\n",
      "2025-01-07 20:41:03.645810: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-01-07 20:41:03.645817: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 3 Chunks of size 12288 totalling 36.0KiB\n",
      "2025-01-07 20:41:03.645823: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 13056 totalling 12.8KiB\n",
      "2025-01-07 20:41:03.645829: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 15104 totalling 14.8KiB\n",
      "2025-01-07 20:41:03.645835: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 45312 totalling 44.2KiB\n",
      "2025-01-07 20:41:03.645842: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 4 Chunks of size 46848 totalling 183.0KiB\n",
      "2025-01-07 20:41:03.645848: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 53248 totalling 52.0KiB\n",
      "2025-01-07 20:41:03.645854: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 2 Chunks of size 93696 totalling 183.0KiB\n",
      "2025-01-07 20:41:03.645861: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 3 Chunks of size 786432 totalling 2.25MiB\n",
      "2025-01-07 20:41:03.645867: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 835584 totalling 816.0KiB\n",
      "2025-01-07 20:41:03.645873: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 2 Chunks of size 3145728 totalling 6.00MiB\n",
      "2025-01-07 20:41:03.645879: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 3232768 totalling 3.08MiB\n",
      "2025-01-07 20:41:03.645885: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 3342336 totalling 3.19MiB\n",
      "2025-01-07 20:41:03.645891: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 5377280 totalling 5.13MiB\n",
      "2025-01-07 20:41:03.645897: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 2 Chunks of size 5988864 totalling 11.42MiB\n",
      "2025-01-07 20:41:03.645903: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 6735360 totalling 6.42MiB\n",
      "2025-01-07 20:41:03.645909: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 7561728 totalling 7.21MiB\n",
      "2025-01-07 20:41:03.645916: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 20054272 totalling 19.12MiB\n",
      "2025-01-07 20:41:03.645922: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 2 Chunks of size 23955456 totalling 45.69MiB\n",
      "2025-01-07 20:41:03.645928: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 81440768 totalling 77.67MiB\n",
      "2025-01-07 20:41:03.645934: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 139102208 totalling 132.66MiB\n",
      "2025-01-07 20:41:03.645941: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1121] Sum Total of in-use chunks: 321.17MiB\n",
      "2025-01-07 20:41:03.645947: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1123] Total bytes in pool: 883163136 memory_limit_: 883163136 available bytes: 0 curr_region_allocation_bytes_: 1766326272\n",
      "2025-01-07 20:41:03.645957: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1128] Stats: \n",
      "Limit:                       883163136\n",
      "InUse:                       336773120\n",
      "MaxInUse:                    842299392\n",
      "NumAllocs:                         896\n",
      "MaxAllocSize:                245156608\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-01-07 20:41:03.645969: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:508] **__________________*************____******_*******_____**********xxxxxxx___________________________\n",
      "2025-01-07 20:41:03.646009: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at matmul_op_impl.h:960 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[16,512,11697] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2025-01-07 20:41:03.646056: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[16,512,11697] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{function_node __inference_one_step_on_data_6313}}{{node gradient_tape/my_model_2_1/dense_2_1/MatMul/MatMul_1}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/my_model_2_1/dense_2_1/MatMul/MatMul_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/derzhapolskii.yv/.conda/envs/py3128/lib/python3.12/asyncio/base_events.py\", line 640, in run_forever\n\n  File \"/home/derzhapolskii.yv/.conda/envs/py3128/lib/python3.12/asyncio/base_events.py\", line 1992, in _run_once\n\n  File \"/home/derzhapolskii.yv/.conda/envs/py3128/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_3631601/1645016690.py\", line 10, in <module>\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 368, in fit\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 216, in function\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 129, in multi_step_on_iterator\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 110, in one_step_on_data\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 75, in train_step\n\nOOM when allocating tensor with shape[16,512,11697] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/my_model_2_1/dense_2_1/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_6361]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m checkpoint_prefix \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;132;01m{epoch}\u001b[39;00m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      7\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcheckpoint_prefix,\n\u001b[1;32m      8\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# callbacks=[checkpoint_callback]\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/tf/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/my_model_2_1/dense_2_1/MatMul/MatMul_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/derzhapolskii.yv/.conda/envs/py3128/lib/python3.12/asyncio/base_events.py\", line 640, in run_forever\n\n  File \"/home/derzhapolskii.yv/.conda/envs/py3128/lib/python3.12/asyncio/base_events.py\", line 1992, in _run_once\n\n  File \"/home/derzhapolskii.yv/.conda/envs/py3128/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_3631601/1645016690.py\", line 10, in <module>\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 368, in fit\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 216, in function\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 129, in multi_step_on_iterator\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 110, in one_step_on_data\n\n  File \"/home/derzhapolskii.yv/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 75, in train_step\n\nOOM when allocating tensor with shape[16,512,11697] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/my_model_2_1/dense_2_1/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_6361]"
     ]
    }
   ],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"checkpoint{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train, \n",
    "    epochs=10, \n",
    "    # callbacks=[checkpoint_callback]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
